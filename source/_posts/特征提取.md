---
title: 特征提取
date: 2018-04-22 20:28:27
tags: Machine Learning
---
#### 文本特征
常见的文本特征包括：一元，二元特征，词性特征，位置信息，以及分词之后词及短语等，当然一般需要去除停用之类的。（后期再补充）
#### 特征提取
在找到一些有用的文本特征之后，每个特征可能会有不同的重要程度，或者特征空间太大，因此需要进行特征选择。   
* 特征项要能够确实标识文本内容;
* 特征项具有将目标文本与其他文本相区分的能力;
* 特征项的个数不能太多;
* 特征项分离要比较容易实现

常用的基于打分（或者投票）的特征提取有：
* TFIDF
* 卡方
* 互信息(Mutual Information)
* 期望交叉熵(Expected Cross Entropy)
* 比值比（Odds ratio, OR）

#### 类别不平衡
很多时候会出现类被不平衡的情况，特别是上述方法，类别多的会占优势。特别是当两个类别非常相似的时候，可以从分词的结果分析，有些应该在在一起的词被分开，导致结果错误的，可以添加到词典里面。

常用的数据不平衡有一下方法：
* 设置损失函数的权重
* 欠采样
  * Edited Nearest Neighbor (ENN) :大部分k近邻样本都跟他自己本身的类别不一样
  * Repeated Edited Nearest Neighbor：反复删除多类别的数据
  * Tomek Link Removal：如果两个类别的数据的最近邻分别数彼此，删除多类别的
* 过采样方法
  * 对少数类有放回的采样（最好控制一个比列，否则容易过拟合）
  * Synthetic Minority Oversampling Technique(SMOTE) （这个方法很给力，能够产生新的数据）
* EasyEnsemble：我觉得可以把多类别的数据分成几分，同时训练多个模型，然后用集成的方法组合一下。这样不会有欠采样数据丢失的情况，也不会有过采样方法的过拟合的情况。

#### 自动特征提取
文本表示是高纬度高稀疏的，特征表达能力很弱。有时候手动提取特征是很麻烦的事情，特别是你对数据没有很深的见解。因此，可以使用神经网络的方法try一下，省时，省力。
* fastText
* TextCNN
* TextRNN 可能短文本效果会好点
* TextRNN + Attention
* TextRCNN 将RNN和CNN结合   

以上的模型对于深度学习来说都是比较简单的，可以快速尝试或者实现。当然目前还是黑盒子的，不好理解why。
***
